<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        var scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          var element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          var hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          var newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((entries) => {
          setHeight();
        });
        resizeObserver.observe(obj.contentWindow.document.body);
      }
    </script>
    <marimo-filename hidden>homework.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>homework</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/index-DKEudB02.js"></script>
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/index-Cx0bsY1w.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "homework.py",
            "mode": "read",
            "version": "0.16.0",
            "serverToken": "static",
            "config": {"ai": {"models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false}, "display": {"cell_output": "above", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": false, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": true}}, "package_management": {"manager": "pip"}, "runtime": {"auto_instantiate": true, "auto_reload": "off", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nfrom torchvision import models, transforms\nfrom PIL import Image", "code_hash": "aa853ac68ae6cc81825de6bbf87d61e0", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n## Homework\n\n> **Note**: it's very likely that in this homework your answers won't match \n> the options exactly. That's okay and expected. Select the option that's\n> closest to your solution.\n> If it's exactly in between two options, select the higher value.\n\"\"\"\n)", "code_hash": "0e9b93839492da20454f3bc6be3904be", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "MJUe", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Dataset\n\nIn this homework, we'll build a model for classifying various hair types. \nFor this, we will use the Hair Type dataset that was obtained from \n[Kaggle](https://www.kaggle.com/datasets/kavyasreeb/hair-type-dataset) \nand slightly rebuilt.\n\nYou can download the target dataset for this homework from \n[here](https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip):\n\n```bash\nwget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\nunzip data.zip\n```\n\nIn the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch. \n\nWe will use PyTorch for that.\n\nYou can use Google Colab or your own computer for that.\n\"\"\"\n)", "code_hash": "15408bf8528f0452a5161d9b18093046", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "vblA", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Data Preparation\n\nThe dataset contains around 1000 images of hairs in the separate folders \nfor training and test sets. \n\n### Reproducibility\n\nReproducibility in deep learning is a multifaceted challenge that requires attention \nto both software and hardware details. In some cases, we can't guarantee exactly the same results during the same experiment runs.\n\nTherefore, in this homework we suggest to set the random number seed generators by:\n\n```python\nimport numpy as np\nimport torch\n\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n```\n\nAlso, use PyTorch of version 2.8.0 (that's the one in Colab).\n\"\"\"\n)", "code_hash": "ba97a5a78ccbea2fc974b762b554499f", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "bkHC", "name": "_"}, {"code": "def set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)", "code_hash": "dbd2a89064b9fc471594ac6ad5d7e8de", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Model\n\nFor this homework we will use Convolutional Neural Network (CNN). We'll use PyTorch.\n\nYou need to develop the model with following structure:\n\n* The shape for input should be `(3, 200, 200)` (channels first format in PyTorch)\n* Next, create a convolutional layer (`nn.Conv2d`):\n    * Use 32 filters (output channels)\n    * Kernel size should be `(3, 3)` (that's the size of the filter)\n    * Use `'relu'` as activation \n* Reduce the size of the feature map with max pooling (`nn.MaxPool2d`)\n    * Set the pooling size to `(2, 2)`\n* Turn the multi-dimensional result into vectors using `flatten` or `view`\n* Next, add a `nn.Linear` layer with 64 neurons and `'relu'` activation\n* Finally, create the `nn.Linear` layer with 1 neuron - this will be the output\n    * The output layer should have an activation - use the appropriate activation for the binary classification case\n\nAs optimizer use `torch.optim.SGD` with the following parameters:\n\n* `torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)`\n\"\"\"\n)", "code_hash": "cbaeb5909e988529c4dbf31465e44093", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "PKri", "name": "_"}, {"code": "import torch.nn as nn\n\nclass BinaryClassification(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.linear = nn.Linear(32 * 99 * 99, 64)\n        self.output = nn.Linear(64, 1)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = self.linear(x)\n        x = self.relu(x)\n        x = self.output(x)\n        return x", "code_hash": "010650c9e6b88394474788708a5d2d9b", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Question 1\n\nWhich loss function you will use?\n\n* `nn.MSELoss()`\n* `nn.BCEWithLogitsLoss()`\n* `nn.CrossEntropyLoss()`\n* `nn.CosineEmbeddingLoss()`\n\n(Multiple answered can be correct, so pick any)\n\"\"\"\n)", "code_hash": "29c2cabf57e4e4739d65688f329c330e", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "SFPL", "name": "_"}, {"code": "mo.md(r\"\"\"I used **nn.BCEWithLogitsLoss()**.\"\"\")", "code_hash": "7ef38e735aa00d7012e3eb398ea01fb9", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "BYtC", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Question 2\n\nWhat's the total number of parameters of the model? You can use `torchsummary` or count manually. \n\nIn PyTorch, you can find the total number of parameters using:\n\n```python\n# Option 1: Using torchsummary (install with: pip install torchsummary)\nfrom torchsummary import summary\nsummary(model, input_size=(3, 200, 200))\n\n# Option 2: Manual counting\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total parameters: {total_params}\")\n```\n\n* 896 \n* 11214912\n* 15896912\n* 20073473\n\"\"\"\n)", "code_hash": "d676a62d0c578a08ea60bfb8f1b340c0", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "RGSE", "name": "_"}, {"code": "mo.md(r\"\"\"The number of parameters of the model is **20073473**, as shown below.\"\"\")", "code_hash": "9db5c13e33b6ec0a386cd5aeffe2df2e", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "Kclp", "name": "_"}, {"code": "def count_model_parameters():\n    model, _, _ = get_classifier()\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Total parameters: {total_params}\")\n\ncount_model_parameters()", "code_hash": "a311fc63cfa300f4dd278ea78e40717c", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "emfo", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Generators and Training\n\nFor the next two questions, use the following transformation for both train and test sets:\n\"\"\"\n)", "code_hash": "01e083290ff044d47bc0774a7d4d1dc8", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "Hstk", "name": "_"}, {"code": "def get_transforms():\n    return transforms.Compose([\n        transforms.Resize((200, 200)),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]\n        )\n    ])", "code_hash": "1ca089f03a325527092d9fc9e5278aee", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "mo.md(r\"\"\"We don't need to do any additional pre-processing for the images.\"\"\")", "code_hash": "ef9a00113877e7032e66c13978da7bf6", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "iLit", "name": "_"}, {"code": "import torch.optim as optim\n\ndef get_device() -> str:\n    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef train(\n    model: nn.Module,\n    optimizer: optim.Adam,\n    criterion: nn.CrossEntropyLoss,\n    train_loader: DataLoader,\n    val_loader: DataLoader,\n    checkpoint_filename: str,\n    num_epochs: int = 10,\n):\n    best_val_accuracy = 0.0\n\n    train_history = {\"accuracy\": [], \"loss\": []}\n    validation_history = {\"accuracy\": [], \"loss\": []}\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1} / {num_epochs}\")\n\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(get_device()), labels.to(get_device())\n            labels = labels.float().unsqueeze(1)\n\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            predicted = (torch.sigmoid(outputs) > 0.5).float()\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_loss = running_loss / len(train_loader)\n        train_acc = correct / total\n\n        train_history[\"loss\"].append(train_loss)\n        train_history[\"accuracy\"].append(train_acc)\n\n        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n\n        val_loss, val_acc = evaluate(model, criterion, val_loader)\n\n        validation_history[\"loss\"].append(train_loss)\n        validation_history[\"accuracy\"].append(train_acc)\n\n        if val_acc > best_val_accuracy:\n            best_val_accuracy = val_acc\n            torch.save(model.state_dict(), checkpoint_filename)\n            print(f\"  Checkpoint saved: {checkpoint_filename}\")\n\n    return train_history, validation_history\n\ndef evaluate(\n    model: nn.Module,\n    criterion: nn.CrossEntropyLoss,\n    val_loader: DataLoader\n) -> tuple[float]:\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(get_device()), labels.to(get_device())\n            labels = labels.float().unsqueeze(1)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item() * inputs.size(0)\n            predicted = (torch.sigmoid(outputs) > 0.5).float()\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_loss /= len(val_loader)\n    val_acc = val_correct / val_total\n    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n    return val_loss, val_acc", "code_hash": "308ec39328439027f2ef150238656cb3", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n* Use `batch_size=20`\n* Use `shuffle=True` for both training, but `False` for test.\n\"\"\"\n)", "code_hash": "aa77a6ea1b2a537abfbce2f61cd8dee1", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "ROlb", "name": "_"}, {"code": "import os\nfrom torch.utils.data import Dataset, DataLoader\n\nclass HomeworkDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.classes = sorted(os.listdir(data_dir))\n        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n\n        for label_name in self.classes:\n            label_dir = os.path.join(data_dir, label_name)\n            for img_name in os.listdir(label_dir):\n                self.image_paths.append(os.path.join(label_dir, img_name))\n                self.labels.append(self.class_to_idx[label_name])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\ndef get_dataloader(split: str, batch_size: int = 20, shuffle: bool = True) -> DataLoader:\n    dataset = HomeworkDataset(\n        data_dir=f\"./module-8/data/homework/{split}\",\n        transform=get_transforms()\n    )\n\n    return DataLoader(dataset, batch_size = batch_size, shuffle = shuffle)\n\ntrain_loader = get_dataloader(\"train\", shuffle=True)\nval_loader = get_dataloader(\"test\", shuffle=False)", "code_hash": "31994f32d5f4242b7d45500f49fc7c3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "qnkX", "name": "_"}, {"code": "mo.md(r\"\"\"Now fit the model.\"\"\")", "code_hash": "552b1d383b60214806a66fb57a27ad67", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "TqIu", "name": "_"}, {"code": "from pathlib import Path\n\nweights_filename = \"./module-8/data/homework-model.torch\"\n\ndef get_classifier() -> tuple[nn.Module, optim.Adam, nn.CrossEntropyLoss]:\n    device = get_device()\n\n    model = BinaryClassification()\n    model.to(device)\n\n    optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n    criterion = nn.BCEWithLogitsLoss()\n\n    return model, optimizer, criterion\n\n# This values were manually written after a train execution\n# Running the training process will reset them\ntrain_history = {\"accuracy\": [0.7965, 0.7965], \"loss\": [-2.948, 2.948]}\nvalidation_history = {\"accuracy\": [], \"loss\": []}\n\nif not Path(weights_filename).exists():\n    print(\"The model weights were not found, so the model will be trained\")\n    model, optimizer, criterion = get_classifier()\n    train_history, validation_history = train(\n        model,\n        optimizer,\n        criterion,\n        train_loader,\n        val_loader,\n        checkpoint_filename = weights_filename,\n        num_epochs = 10,\n    )\nelse:\n    print(\"The model weights were found, so the model weights will be loaded and the model will be evaluated\")\n    model, optimizer, criterion = get_classifier()\n    model.load_state_dict(torch.load(weights_filename, weights_only=True))\n    evaluate(\n        model,\n        criterion,\n        val_loader,\n    )\n\ntrain_history, validation_history", "code_hash": "be601263fe0e0fc89bfc78adb7f22036", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Vxnm", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Question 3\n\nWhat is the median of training accuracy for all the epochs for this model?\n\n* 0.05\n* 0.12\n* 0.40\n* 0.84\n\"\"\"\n)", "code_hash": "43a2c6f13843dbff9b6b5e387c70ef4a", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "DnEU", "name": "_"}, {"code": "mo.md(r\"\"\"After a training, the following expression returned 0.7965, so the closest suggested option is **0.84**.\"\"\")", "code_hash": "1b027ce0d71523d2d0de9f6c2383245a", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "ulZA", "name": "_"}, {"code": "np.median(train_history[\"accuracy\"])", "code_hash": "f2fbd347e525ddc44493e08fadd94806", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ecfG", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Question 4\n\nWhat is the standard deviation of training loss for all the epochs for this model?\n\n* 0.007\n* 0.078\n* 0.171\n* 1.710\n\"\"\"\n)", "code_hash": "101241fe6fac303922c16294b5f04789", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "Pvdt", "name": "_"}, {"code": "mo.md(r\"\"\"After a training, the following expression returned 2.948, so the closest suggested option is **1.710**.\"\"\")", "code_hash": "df12eed871bbefe1b534916e0446107f", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "ZBYS", "name": "_"}, {"code": "np.std(train_history[\"loss\"])", "code_hash": "23bdad4984d736109f395d726baf7fcf", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aLJB", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Data Augmentation\n\nFor the next two questions, we'll generate more data using data augmentations. \n\nAdd the following augmentations to your training data generator:\n\n```python\ntransforms.RandomRotation(50),\ntransforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\ntransforms.RandomHorizontalFlip(),\n```\n\"\"\"\n)", "code_hash": "10b6354fac3c0037e40aec952f5ba156", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "nHfw", "name": "_"}, {"code": "def get_augmented_transforms():\n    return transforms.Compose([\n        transforms.RandomRotation(50),\n        transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n        transforms.RandomHorizontalFlip(),\n        transforms.Resize((200, 200)),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]\n        )\n    ])", "code_hash": "92682ab8dd8096ddc52cfb4889a19e10", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PWJt", "name": "_"}, {"code": "def get_augmented_dataloader(split: str, batch_size: int = 20, shuffle: bool = True) -> DataLoader:\n    dataset = HomeworkDataset(\n        data_dir=f\"./module-8/data/homework/{split}\",\n        transform=get_augmented_transforms()\n    )\n\n    return DataLoader(dataset, batch_size = batch_size, shuffle = shuffle)\n\ntrain_augmented_loader = get_augmented_dataloader(\"train\", shuffle=True)\nval_augmented_loader = get_augmented_dataloader(\"test\", shuffle=False)", "code_hash": "e8bd102fa37a55e1ae68ab1281cd1a31", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Yyes", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Question 5 \n\nLet's train our model for 10 more epochs using the same code as previously.\n\n> **Note:** make sure you don't re-create the model.\n> we want to continue training the model we already started training.\n\"\"\"\n)", "code_hash": "8bfd439061fae1a51b3f2ada48f2a532", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "xXTn", "name": "_"}, {"code": "augmented_weights_filename = \"./module-8/data/homework-augmented_model.torch\"\n\n# This values were manually written after a train execution\n# Running the training process will reset them\naugmented_train_history = {\"accuracy\": [], \"loss\": [10.44]}\naugmented_validation_history = {\"accuracy\": [0.7523, 0.7523, 0.7523, 0.7523, 0.7523, 0.7523], \"loss\": []}\n\nif not Path(augmented_weights_filename).exists():\n    print(\"The model weights were not found, so the model will be trained\")\n    augmented_train_history, augmented_validation_history = train(\n        model,\n        optimizer,\n        criterion,\n        train_augmented_loader,\n        val_augmented_loader,\n        checkpoint_filename = augmented_weights_filename,\n        num_epochs = 10,\n    )\nelse:\n    print(\"The model weights were found, so the model weights will be loaded and the model will be evaluated\")\n    augmented_model, augmented_optimizer, augmented_criterion = get_classifier()\n    augmented_model.load_state_dict(torch.load(augmented_weights_filename, weights_only=True))\n    evaluate(\n        augmented_model,\n        augmented_criterion,\n        val_augmented_loader,\n    )\n\naugmented_train_history, augmented_validation_history", "code_hash": "c2d4588c8bc90127844c05be19c995da", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "YnWZ", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\nWhat is the mean of test loss for all the epochs for the model trained with augmentations?\n\n* 0.008\n* 0.08\n* 0.88\n* 8.88\n\"\"\"\n)", "code_hash": "af93f3bb8d81d5e59573dfc819fb59ae", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "bVhz", "name": "_"}, {"code": "mo.md(r\"\"\"The mean of the loss for the augmented epochs is 10.44. The closest suggested option is **8.88**.\"\"\")", "code_hash": "2dcdc8b61baf478feecf5d588315f625", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "TzJI", "name": "_"}, {"code": "np.mean(augmented_train_history[\"loss\"])", "code_hash": "a2f9acbcbdc51f50d376177f74b53a0d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "AvKC", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n### Question 6\n\nWhat's the average of test accuracy for the last 5 epochs (from 6 to 10)\nfor the model trained with augmentations?\n\n* 0.08\n* 0.28\n* 0.68\n* 0.98\n\"\"\"\n)", "code_hash": "43738b129617aea81451dc43fc8d5893", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "AjVT", "name": "_"}, {"code": "mo.md(r\"\"\"The average test accuracy for the last 5 epochs trained with augmentations is 0.7523, and the closest suggested option is **0.68**.\"\"\")", "code_hash": "ddb7cb3705b5dd76514ea5893d69ea08", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "ylqt", "name": "_"}, {"code": "np.average(augmented_validation_history[\"accuracy\"][5:])", "code_hash": "8441e2cf60f69123da49ea09ecab23ea", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "rcgR", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n## Submit the results\n\n* Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw08\n* If your answer doesn't match options exactly, select the closest one. If the answer is exactly in between two options, select the higher value.\n\"\"\"\n)", "code_hash": "1f1164bd530e8aa38c524c8d2851a24c", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "pHFh", "name": "_"}], "metadata": {"marimo_version": "0.16.0"}, "version": "1"},
            "session": {"cells": [{"code_hash": "aa853ac68ae6cc81825de6bbf87d61e0", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "0e9b93839492da20454f3bc6be3904be", "console": [], "id": "MJUe", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"homework\">Homework</h2>\n<blockquote>\n<span class=\"paragraph\"><strong>Note</strong>: it's very likely that in this homework your answers won't match \nthe options exactly. That's okay and expected. Select the option that's\nclosest to your solution.\nIf it's exactly in between two options, select the higher value.</span>\n</blockquote></span>"}, "type": "data"}]}, {"code_hash": "15408bf8528f0452a5161d9b18093046", "console": [], "id": "vblA", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"dataset\">Dataset</h3>\n<span class=\"paragraph\">In this homework, we'll build a model for classifying various hair types. \nFor this, we will use the Hair Type dataset that was obtained from \n<a href=\"https://www.kaggle.com/datasets/kavyasreeb/hair-type-dataset\" rel=\"noopener\" target=\"_blank\">Kaggle</a> \nand slightly rebuilt.</span>\n<span class=\"paragraph\">You can download the target dataset for this homework from \n<a href=\"https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\" rel=\"noopener\" target=\"_blank\">here</a>:</span>\n<div class=\"language-bash codehilite\"><pre><span></span><code>wget<span class=\"w\"> </span>https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\nunzip<span class=\"w\"> </span>data.zip\n</code></pre></div>\n<span class=\"paragraph\">In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch. </span>\n<span class=\"paragraph\">We will use PyTorch for that.</span>\n<span class=\"paragraph\">You can use Google Colab or your own computer for that.</span></span>"}, "type": "data"}]}, {"code_hash": "ba97a5a78ccbea2fc974b762b554499f", "console": [], "id": "bkHC", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"data-preparation\">Data Preparation</h3>\n<span class=\"paragraph\">The dataset contains around 1000 images of hairs in the separate folders \nfor training and test sets. </span>\n<h3 id=\"reproducibility\">Reproducibility</h3>\n<span class=\"paragraph\">Reproducibility in deep learning is a multifaceted challenge that requires attention \nto both software and hardware details. In some cases, we can't guarantee exactly the same results during the same experiment runs.</span>\n<span class=\"paragraph\">Therefore, in this homework we suggest to set the random number seed generators by:</span>\n<div class=\"language-python codehilite\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">numpy</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"nn\">np</span>\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">torch</span>\n\n<span class=\"n\">SEED</span> <span class=\"o\">=</span> <span class=\"mi\">42</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">SEED</span><span class=\"p\">)</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">manual_seed</span><span class=\"p\">(</span><span class=\"n\">SEED</span><span class=\"p\">)</span>\n\n<span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">():</span>\n    <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">manual_seed</span><span class=\"p\">(</span><span class=\"n\">SEED</span><span class=\"p\">)</span>\n    <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">manual_seed_all</span><span class=\"p\">(</span><span class=\"n\">SEED</span><span class=\"p\">)</span>\n\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">backends</span><span class=\"o\">.</span><span class=\"n\">cudnn</span><span class=\"o\">.</span><span class=\"n\">deterministic</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">backends</span><span class=\"o\">.</span><span class=\"n\">cudnn</span><span class=\"o\">.</span><span class=\"n\">benchmark</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n</code></pre></div>\n<span class=\"paragraph\">Also, use PyTorch of version 2.8.0 (that's the one in Colab).</span></span>"}, "type": "data"}]}, {"code_hash": "dbd2a89064b9fc471594ac6ad5d7e8de", "console": [], "id": "lEQa", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "cbaeb5909e988529c4dbf31465e44093", "console": [], "id": "PKri", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"model\">Model</h3>\n<span class=\"paragraph\">For this homework we will use Convolutional Neural Network (CNN). We'll use PyTorch.</span>\n<span class=\"paragraph\">You need to develop the model with following structure:</span>\n<ul>\n<li>The shape for input should be <code>(3, 200, 200)</code> (channels first format in PyTorch)</li>\n<li>Next, create a convolutional layer (<code>nn.Conv2d</code>):<ul>\n<li>Use 32 filters (output channels)</li>\n<li>Kernel size should be <code>(3, 3)</code> (that's the size of the filter)</li>\n<li>Use <code>'relu'</code> as activation </li>\n</ul>\n</li>\n<li>Reduce the size of the feature map with max pooling (<code>nn.MaxPool2d</code>)<ul>\n<li>Set the pooling size to <code>(2, 2)</code></li>\n</ul>\n</li>\n<li>Turn the multi-dimensional result into vectors using <code>flatten</code> or <code>view</code></li>\n<li>Next, add a <code>nn.Linear</code> layer with 64 neurons and <code>'relu'</code> activation</li>\n<li>Finally, create the <code>nn.Linear</code> layer with 1 neuron - this will be the output<ul>\n<li>The output layer should have an activation - use the appropriate activation for the binary classification case</li>\n</ul>\n</li>\n</ul>\n<span class=\"paragraph\">As optimizer use <code>torch.optim.SGD</code> with the following parameters:</span>\n<ul>\n<li><code>torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)</code></li>\n</ul></span>"}, "type": "data"}]}, {"code_hash": "010650c9e6b88394474788708a5d2d9b", "console": [], "id": "Xref", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "29c2cabf57e4e4739d65688f329c330e", "console": [], "id": "SFPL", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"question-1\">Question 1</h3>\n<span class=\"paragraph\">Which loss function you will use?</span>\n<ul>\n<li><code>nn.MSELoss()</code></li>\n<li><code>nn.BCEWithLogitsLoss()</code></li>\n<li><code>nn.CrossEntropyLoss()</code></li>\n<li><code>nn.CosineEmbeddingLoss()</code></li>\n</ul>\n<span class=\"paragraph\">(Multiple answered can be correct, so pick any)</span></span>"}, "type": "data"}]}, {"code_hash": "7ef38e735aa00d7012e3eb398ea01fb9", "console": [], "id": "BYtC", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">I used <strong>nn.BCEWithLogitsLoss()</strong>.</span></span>"}, "type": "data"}]}, {"code_hash": "d676a62d0c578a08ea60bfb8f1b340c0", "console": [], "id": "RGSE", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"question-2\">Question 2</h3>\n<span class=\"paragraph\">What's the total number of parameters of the model? You can use <code>torchsummary</code> or count manually. </span>\n<span class=\"paragraph\">In PyTorch, you can find the total number of parameters using:</span>\n<div class=\"language-python codehilite\"><pre><span></span><code><span class=\"c1\"># Option 1: Using torchsummary (install with: pip install torchsummary)</span>\n<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">torchsummary</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">summary</span>\n<span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">input_size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">200</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Option 2: Manual counting</span>\n<span class=\"n\">total_params</span> <span class=\"o\">=</span> <span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Total parameters: </span><span class=\"si\">{</span><span class=\"n\">total_params</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n</code></pre></div>\n<ul>\n<li>896 </li>\n<li>11214912</li>\n<li>15896912</li>\n<li>20073473</li>\n</ul></span>"}, "type": "data"}]}, {"code_hash": "9db5c13e33b6ec0a386cd5aeffe2df2e", "console": [], "id": "Kclp", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">The number of parameters of the model is <strong>20073473</strong>, as shown below.</span></span>"}, "type": "data"}]}, {"code_hash": "a311fc63cfa300f4dd278ea78e40717c", "console": [{"name": "stdout", "text": "Total parameters: 20073473\n", "type": "stream"}], "id": "emfo", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "01e083290ff044d47bc0774a7d4d1dc8", "console": [], "id": "Hstk", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"generators-and-training\">Generators and Training</h3>\n<span class=\"paragraph\">For the next two questions, use the following transformation for both train and test sets:</span></span>"}, "type": "data"}]}, {"code_hash": "1ca089f03a325527092d9fc9e5278aee", "console": [], "id": "nWHF", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "ef9a00113877e7032e66c13978da7bf6", "console": [], "id": "iLit", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">We don't need to do any additional pre-processing for the images.</span></span>"}, "type": "data"}]}, {"code_hash": "308ec39328439027f2ef150238656cb3", "console": [], "id": "ZHCJ", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "aa77a6ea1b2a537abfbce2f61cd8dee1", "console": [], "id": "ROlb", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><ul>\n<li>Use <code>batch_size=20</code></li>\n<li>Use <code>shuffle=True</code> for both training, but <code>False</code> for test.</li>\n</ul></span>"}, "type": "data"}]}, {"code_hash": "31994f32d5f4242b7d45500f49fc7c3e", "console": [], "id": "qnkX", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "552b1d383b60214806a66fb57a27ad67", "console": [], "id": "TqIu", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">Now fit the model.</span></span>"}, "type": "data"}]}, {"code_hash": "be601263fe0e0fc89bfc78adb7f22036", "console": [{"name": "stdout", "text": "The model weights were found, so the model weights will be loaded and the model will be evaluated\n", "type": "stream"}, {"name": "stdout", "text": "  Val Loss: 13.8005, Val Acc: 0.7214\n", "type": "stream"}], "id": "Vxnm", "outputs": [{"data": {"application/json": "[{\"accuracy\": [\"text/plain+float:0.7965\", \"text/plain+float:0.7965\"], \"loss\": [\"text/plain+float:-2.948\", \"text/plain+float:2.948\"]}, {\"accuracy\": [], \"loss\": []}]"}, "type": "data"}]}, {"code_hash": "43a2c6f13843dbff9b6b5e387c70ef4a", "console": [], "id": "DnEU", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"question-3\">Question 3</h3>\n<span class=\"paragraph\">What is the median of training accuracy for all the epochs for this model?</span>\n<ul>\n<li>0.05</li>\n<li>0.12</li>\n<li>0.40</li>\n<li>0.84</li>\n</ul></span>"}, "type": "data"}]}, {"code_hash": "1b027ce0d71523d2d0de9f6c2383245a", "console": [], "id": "ulZA", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">After a training, the following expression returned 0.7965, so the closest suggested option is <strong>0.84</strong>.</span></span>"}, "type": "data"}]}, {"code_hash": "f2fbd347e525ddc44493e08fadd94806", "console": [], "id": "ecfG", "outputs": [{"data": {"text/html": "<pre style='font-size: 12px'>np.float64(0.7965)</pre>"}, "type": "data"}]}, {"code_hash": "101241fe6fac303922c16294b5f04789", "console": [], "id": "Pvdt", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"question-4\">Question 4</h3>\n<span class=\"paragraph\">What is the standard deviation of training loss for all the epochs for this model?</span>\n<ul>\n<li>0.007</li>\n<li>0.078</li>\n<li>0.171</li>\n<li>1.710</li>\n</ul></span>"}, "type": "data"}]}, {"code_hash": "df12eed871bbefe1b534916e0446107f", "console": [], "id": "ZBYS", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">After a training, the following expression returned 2.948, so the closest suggested option is <strong>1.710</strong>.</span></span>"}, "type": "data"}]}, {"code_hash": "23bdad4984d736109f395d726baf7fcf", "console": [], "id": "aLJB", "outputs": [{"data": {"text/html": "<pre style='font-size: 12px'>np.float64(2.948)</pre>"}, "type": "data"}]}, {"code_hash": "10b6354fac3c0037e40aec952f5ba156", "console": [], "id": "nHfw", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"data-augmentation\">Data Augmentation</h3>\n<span class=\"paragraph\">For the next two questions, we'll generate more data using data augmentations. </span>\n<span class=\"paragraph\">Add the following augmentations to your training data generator:</span>\n<div class=\"language-python codehilite\"><pre><span></span><code><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">RandomRotation</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">),</span>\n<span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">RandomResizedCrop</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mf\">0.9</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span><span class=\"p\">),</span> <span class=\"n\">ratio</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mf\">0.9</span><span class=\"p\">,</span> <span class=\"mf\">1.1</span><span class=\"p\">)),</span>\n<span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">RandomHorizontalFlip</span><span class=\"p\">(),</span>\n</code></pre></div></span>"}, "type": "data"}]}, {"code_hash": "92682ab8dd8096ddc52cfb4889a19e10", "console": [], "id": "PWJt", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "e8bd102fa37a55e1ae68ab1281cd1a31", "console": [], "id": "Yyes", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "8bfd439061fae1a51b3f2ada48f2a532", "console": [], "id": "xXTn", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"question-5\">Question 5</h3>\n<span class=\"paragraph\">Let's train our model for 10 more epochs using the same code as previously.</span>\n<blockquote>\n<span class=\"paragraph\"><strong>Note:</strong> make sure you don't re-create the model.\nwe want to continue training the model we already started training.</span>\n</blockquote></span>"}, "type": "data"}]}, {"code_hash": "c2d4588c8bc90127844c05be19c995da", "console": [{"name": "stdout", "text": "The model weights were found, so the model weights will be loaded and the model will be evaluated\n", "type": "stream"}, {"name": "stdout", "text": "  Val Loss: 9.2998, Val Acc: 0.7363\n", "type": "stream"}], "id": "YnWZ", "outputs": [{"data": {"application/json": "[{\"accuracy\": [], \"loss\": [\"text/plain+float:10.44\"]}, {\"accuracy\": [\"text/plain+float:0.7523\", \"text/plain+float:0.7523\", \"text/plain+float:0.7523\", \"text/plain+float:0.7523\", \"text/plain+float:0.7523\", \"text/plain+float:0.7523\"], \"loss\": []}]"}, "type": "data"}]}, {"code_hash": "af93f3bb8d81d5e59573dfc819fb59ae", "console": [], "id": "bVhz", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">What is the mean of test loss for all the epochs for the model trained with augmentations?</span>\n<ul>\n<li>0.008</li>\n<li>0.08</li>\n<li>0.88</li>\n<li>8.88</li>\n</ul></span>"}, "type": "data"}]}, {"code_hash": "2dcdc8b61baf478feecf5d588315f625", "console": [], "id": "TzJI", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">The mean of the loss for the augmented epochs is 10.44. The closest suggested option is <strong>8.88</strong>.</span></span>"}, "type": "data"}]}, {"code_hash": "a2f9acbcbdc51f50d376177f74b53a0d", "console": [], "id": "AvKC", "outputs": [{"data": {"text/html": "<pre style='font-size: 12px'>np.float64(10.44)</pre>"}, "type": "data"}]}, {"code_hash": "43738b129617aea81451dc43fc8d5893", "console": [], "id": "AjVT", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"question-6\">Question 6</h3>\n<span class=\"paragraph\">What's the average of test accuracy for the last 5 epochs (from 6 to 10)\nfor the model trained with augmentations?</span>\n<ul>\n<li>0.08</li>\n<li>0.28</li>\n<li>0.68</li>\n<li>0.98</li>\n</ul></span>"}, "type": "data"}]}, {"code_hash": "ddb7cb3705b5dd76514ea5893d69ea08", "console": [], "id": "ylqt", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">The average test accuracy for the last 5 epochs trained with augmentations is 0.7523, and the closest suggested option is <strong>0.68</strong>.</span></span>"}, "type": "data"}]}, {"code_hash": "8441e2cf60f69123da49ea09ecab23ea", "console": [], "id": "rcgR", "outputs": [{"data": {"text/html": "<pre style='font-size: 12px'>np.float64(0.7523)</pre>"}, "type": "data"}]}, {"code_hash": "1f1164bd530e8aa38c524c8d2851a24c", "console": [], "id": "pHFh", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"submit-the-results\">Submit the results</h2>\n<ul>\n<li>Submit your results here: <a href=\"https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw08\" rel=\"noopener\" target=\"_blank\">https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw08</a></li>\n<li>If your answer doesn't match options exactly, select the closest one. If the answer is exactly in between two options, select the higher value.</li>\n</ul></span>"}, "type": "data"}]}], "metadata": {"marimo_version": "0.16.0"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.16.0%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20import%20pandas%20as%20pd%0A%20%20%20%20import%20numpy%20as%20np%0A%20%20%20%20import%20matplotlib.pyplot%20as%20plt%0A%20%20%20%20import%20seaborn%20as%20sns%0A%20%20%20%20import%20torch%0A%20%20%20%20from%20torchvision%20import%20models%2C%20transforms%0A%20%20%20%20from%20PIL%20import%20Image%0A%20%20%20%20return%20Image%2C%20mo%2C%20np%2C%20torch%2C%20transforms%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%20Homework%0A%0A%20%20%20%20%3E%20**Note**%3A%20it's%20very%20likely%20that%20in%20this%20homework%20your%20answers%20won't%20match%20%0A%20%20%20%20%3E%20the%20options%20exactly.%20That's%20okay%20and%20expected.%20Select%20the%20option%20that's%0A%20%20%20%20%3E%20closest%20to%20your%20solution.%0A%20%20%20%20%3E%20If%20it's%20exactly%20in%20between%20two%20options%2C%20select%20the%20higher%20value.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Dataset%0A%0A%20%20%20%20In%20this%20homework%2C%20we'll%20build%20a%20model%20for%20classifying%20various%20hair%20types.%20%0A%20%20%20%20For%20this%2C%20we%20will%20use%20the%20Hair%20Type%20dataset%20that%20was%20obtained%20from%20%0A%20%20%20%20%5BKaggle%5D(https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fkavyasreeb%2Fhair-type-dataset)%20%0A%20%20%20%20and%20slightly%20rebuilt.%0A%0A%20%20%20%20You%20can%20download%20the%20target%20dataset%20for%20this%20homework%20from%20%0A%20%20%20%20%5Bhere%5D(https%3A%2F%2Fgithub.com%2FSVizor42%2FML_Zoomcamp%2Freleases%2Fdownload%2Fstraight-curly-data%2Fdata.zip)%3A%0A%0A%20%20%20%20%60%60%60bash%0A%20%20%20%20wget%20https%3A%2F%2Fgithub.com%2FSVizor42%2FML_Zoomcamp%2Freleases%2Fdownload%2Fstraight-curly-data%2Fdata.zip%0A%20%20%20%20unzip%20data.zip%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20In%20the%20lectures%20we%20saw%20how%20to%20use%20a%20pre-trained%20neural%20network.%20In%20the%20homework%2C%20we'll%20train%20a%20much%20smaller%20model%20from%20scratch.%20%0A%0A%20%20%20%20We%20will%20use%20PyTorch%20for%20that.%0A%0A%20%20%20%20You%20can%20use%20Google%20Colab%20or%20your%20own%20computer%20for%20that.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Data%20Preparation%0A%0A%20%20%20%20The%20dataset%20contains%20around%201000%20images%20of%20hairs%20in%20the%20separate%20folders%20%0A%20%20%20%20for%20training%20and%20test%20sets.%20%0A%0A%20%20%20%20%23%23%23%20Reproducibility%0A%0A%20%20%20%20Reproducibility%20in%20deep%20learning%20is%20a%20multifaceted%20challenge%20that%20requires%20attention%20%0A%20%20%20%20to%20both%20software%20and%20hardware%20details.%20In%20some%20cases%2C%20we%20can't%20guarantee%20exactly%20the%20same%20results%20during%20the%20same%20experiment%20runs.%0A%0A%20%20%20%20Therefore%2C%20in%20this%20homework%20we%20suggest%20to%20set%20the%20random%20number%20seed%20generators%20by%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20import%20numpy%20as%20np%0A%20%20%20%20import%20torch%0A%0A%20%20%20%20SEED%20%3D%2042%0A%20%20%20%20np.random.seed(SEED)%0A%20%20%20%20torch.manual_seed(SEED)%0A%0A%20%20%20%20if%20torch.cuda.is_available()%3A%0A%20%20%20%20%20%20%20%20torch.cuda.manual_seed(SEED)%0A%20%20%20%20%20%20%20%20torch.cuda.manual_seed_all(SEED)%0A%0A%20%20%20%20torch.backends.cudnn.deterministic%20%3D%20True%0A%20%20%20%20torch.backends.cudnn.benchmark%20%3D%20False%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20Also%2C%20use%20PyTorch%20of%20version%202.8.0%20(that's%20the%20one%20in%20Colab).%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(np%2C%20torch)%3A%0A%20%20%20%20def%20set_seed(seed)%3A%0A%20%20%20%20%20%20%20%20np.random.seed(seed)%0A%20%20%20%20%20%20%20%20torch.manual_seed(seed)%0A%0A%20%20%20%20%20%20%20%20if%20torch.cuda.is_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20torch.cuda.manual_seed(seed)%0A%20%20%20%20%20%20%20%20%20%20%20%20torch.cuda.manual_seed_all(seed)%0A%0A%20%20%20%20%20%20%20%20torch.backends.cudnn.deterministic%20%3D%20True%0A%20%20%20%20%20%20%20%20torch.backends.cudnn.benchmark%20%3D%20False%0A%0A%20%20%20%20set_seed(42)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Model%0A%0A%20%20%20%20For%20this%20homework%20we%20will%20use%20Convolutional%20Neural%20Network%20(CNN).%20We'll%20use%20PyTorch.%0A%0A%20%20%20%20You%20need%20to%20develop%20the%20model%20with%20following%20structure%3A%0A%0A%20%20%20%20*%20The%20shape%20for%20input%20should%20be%20%60(3%2C%20200%2C%20200)%60%20(channels%20first%20format%20in%20PyTorch)%0A%20%20%20%20*%20Next%2C%20create%20a%20convolutional%20layer%20(%60nn.Conv2d%60)%3A%0A%20%20%20%20%20%20%20%20*%20Use%2032%20filters%20(output%20channels)%0A%20%20%20%20%20%20%20%20*%20Kernel%20size%20should%20be%20%60(3%2C%203)%60%20(that's%20the%20size%20of%20the%20filter)%0A%20%20%20%20%20%20%20%20*%20Use%20%60'relu'%60%20as%20activation%20%0A%20%20%20%20*%20Reduce%20the%20size%20of%20the%20feature%20map%20with%20max%20pooling%20(%60nn.MaxPool2d%60)%0A%20%20%20%20%20%20%20%20*%20Set%20the%20pooling%20size%20to%20%60(2%2C%202)%60%0A%20%20%20%20*%20Turn%20the%20multi-dimensional%20result%20into%20vectors%20using%20%60flatten%60%20or%20%60view%60%0A%20%20%20%20*%20Next%2C%20add%20a%20%60nn.Linear%60%20layer%20with%2064%20neurons%20and%20%60'relu'%60%20activation%0A%20%20%20%20*%20Finally%2C%20create%20the%20%60nn.Linear%60%20layer%20with%201%20neuron%20-%20this%20will%20be%20the%20output%0A%20%20%20%20%20%20%20%20*%20The%20output%20layer%20should%20have%20an%20activation%20-%20use%20the%20appropriate%20activation%20for%20the%20binary%20classification%20case%0A%0A%20%20%20%20As%20optimizer%20use%20%60torch.optim.SGD%60%20with%20the%20following%20parameters%3A%0A%0A%20%20%20%20*%20%60torch.optim.SGD(model.parameters()%2C%20lr%3D0.002%2C%20momentum%3D0.8)%60%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(torch)%3A%0A%20%20%20%20import%20torch.nn%20as%20nn%0A%0A%20%20%20%20class%20BinaryClassification(nn.Module)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20super().__init__()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.conv%20%3D%20nn.Conv2d(in_channels%3D3%2C%20out_channels%3D32%2C%20kernel_size%3D3)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.relu%20%3D%20nn.ReLU()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.pool%20%3D%20nn.MaxPool2d(kernel_size%3D2%2C%20stride%3D2)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.linear%20%3D%20nn.Linear(32%20*%2099%20*%2099%2C%2064)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.output%20%3D%20nn.Linear(64%2C%201)%0A%0A%20%20%20%20%20%20%20%20def%20forward(self%2C%20x)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20x%20%3D%20self.conv(x)%0A%20%20%20%20%20%20%20%20%20%20%20%20x%20%3D%20self.relu(x)%0A%20%20%20%20%20%20%20%20%20%20%20%20x%20%3D%20self.pool(x)%0A%20%20%20%20%20%20%20%20%20%20%20%20x%20%3D%20torch.flatten(x%2C%201)%0A%20%20%20%20%20%20%20%20%20%20%20%20x%20%3D%20self.linear(x)%0A%20%20%20%20%20%20%20%20%20%20%20%20x%20%3D%20self.relu(x)%0A%20%20%20%20%20%20%20%20%20%20%20%20x%20%3D%20self.output(x)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20x%0A%20%20%20%20return%20BinaryClassification%2C%20nn%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Question%201%0A%0A%20%20%20%20Which%20loss%20function%20you%20will%20use%3F%0A%0A%20%20%20%20*%20%60nn.MSELoss()%60%0A%20%20%20%20*%20%60nn.BCEWithLogitsLoss()%60%0A%20%20%20%20*%20%60nn.CrossEntropyLoss()%60%0A%20%20%20%20*%20%60nn.CosineEmbeddingLoss()%60%0A%0A%20%20%20%20(Multiple%20answered%20can%20be%20correct%2C%20so%20pick%20any)%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22I%20used%20**nn.BCEWithLogitsLoss()**.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Question%202%0A%0A%20%20%20%20What's%20the%20total%20number%20of%20parameters%20of%20the%20model%3F%20You%20can%20use%20%60torchsummary%60%20or%20count%20manually.%20%0A%0A%20%20%20%20In%20PyTorch%2C%20you%20can%20find%20the%20total%20number%20of%20parameters%20using%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Option%201%3A%20Using%20torchsummary%20(install%20with%3A%20pip%20install%20torchsummary)%0A%20%20%20%20from%20torchsummary%20import%20summary%0A%20%20%20%20summary(model%2C%20input_size%3D(3%2C%20200%2C%20200))%0A%0A%20%20%20%20%23%20Option%202%3A%20Manual%20counting%0A%20%20%20%20total_params%20%3D%20sum(p.numel()%20for%20p%20in%20model.parameters())%0A%20%20%20%20print(f%22Total%20parameters%3A%20%7Btotal_params%7D%22)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20*%20896%20%0A%20%20%20%20*%2011214912%0A%20%20%20%20*%2015896912%0A%20%20%20%20*%2020073473%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22The%20number%20of%20parameters%20of%20the%20model%20is%20**20073473**%2C%20as%20shown%20below.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(get_classifier)%3A%0A%20%20%20%20def%20count_model_parameters()%3A%0A%20%20%20%20%20%20%20%20model%2C%20_%2C%20_%20%3D%20get_classifier()%0A%20%20%20%20%20%20%20%20total_params%20%3D%20sum(p.numel()%20for%20p%20in%20model.parameters())%0A%20%20%20%20%20%20%20%20print(f%22Total%20parameters%3A%20%7Btotal_params%7D%22)%0A%0A%20%20%20%20count_model_parameters()%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Generators%20and%20Training%0A%0A%20%20%20%20For%20the%20next%20two%20questions%2C%20use%20the%20following%20transformation%20for%20both%20train%20and%20test%20sets%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(transforms)%3A%0A%20%20%20%20def%20get_transforms()%3A%0A%20%20%20%20%20%20%20%20return%20transforms.Compose(%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.Resize((200%2C%20200))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.ToTensor()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.Normalize(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mean%3D%5B0.485%2C%200.456%2C%200.406%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20std%3D%5B0.229%2C%200.224%2C%200.225%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%5D)%0A%20%20%20%20return%20(get_transforms%2C)%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22We%20don't%20need%20to%20do%20any%20additional%20pre-processing%20for%20the%20images.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(DataLoader%2C%20nn%2C%20torch)%3A%0A%20%20%20%20import%20torch.optim%20as%20optim%0A%0A%20%20%20%20def%20get_device()%20-%3E%20str%3A%0A%20%20%20%20%20%20%20%20return%20torch.device(%22cuda%22%20if%20torch.cuda.is_available()%20else%20%22cpu%22)%0A%0A%20%20%20%20def%20train(%0A%20%20%20%20%20%20%20%20model%3A%20nn.Module%2C%0A%20%20%20%20%20%20%20%20optimizer%3A%20optim.Adam%2C%0A%20%20%20%20%20%20%20%20criterion%3A%20nn.CrossEntropyLoss%2C%0A%20%20%20%20%20%20%20%20train_loader%3A%20DataLoader%2C%0A%20%20%20%20%20%20%20%20val_loader%3A%20DataLoader%2C%0A%20%20%20%20%20%20%20%20checkpoint_filename%3A%20str%2C%0A%20%20%20%20%20%20%20%20num_epochs%3A%20int%20%3D%2010%2C%0A%20%20%20%20)%3A%0A%20%20%20%20%20%20%20%20best_val_accuracy%20%3D%200.0%0A%0A%20%20%20%20%20%20%20%20train_history%20%3D%20%7B%22accuracy%22%3A%20%5B%5D%2C%20%22loss%22%3A%20%5B%5D%7D%0A%20%20%20%20%20%20%20%20validation_history%20%3D%20%7B%22accuracy%22%3A%20%5B%5D%2C%20%22loss%22%3A%20%5B%5D%7D%0A%0A%20%20%20%20%20%20%20%20for%20epoch%20in%20range(num_epochs)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Epoch%20%7Bepoch%2B1%7D%20%2F%20%7Bnum_epochs%7D%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20model.train()%0A%20%20%20%20%20%20%20%20%20%20%20%20running_loss%20%3D%200.0%0A%20%20%20%20%20%20%20%20%20%20%20%20correct%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20total%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20inputs%2C%20labels%20in%20train_loader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20inputs%2C%20labels%20%3D%20inputs.to(get_device())%2C%20labels.to(get_device())%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20labels%20%3D%20labels.float().unsqueeze(1)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20optimizer.zero_grad()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20outputs%20%3D%20model(inputs)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss%20%3D%20criterion(outputs%2C%20labels)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss.backward()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20optimizer.step()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20running_loss%20%2B%3D%20loss.item()%20*%20inputs.size(0)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20predicted%20%3D%20(torch.sigmoid(outputs)%20%3E%200.5).float()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20total%20%2B%3D%20labels.size(0)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20correct%20%2B%3D%20(predicted%20%3D%3D%20labels).sum().item()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20train_loss%20%3D%20running_loss%20%2F%20len(train_loader)%0A%20%20%20%20%20%20%20%20%20%20%20%20train_acc%20%3D%20correct%20%2F%20total%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20train_history%5B%22loss%22%5D.append(train_loss)%0A%20%20%20%20%20%20%20%20%20%20%20%20train_history%5B%22accuracy%22%5D.append(train_acc)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Train%20Loss%3A%20%7Btrain_loss%3A.4f%7D%2C%20Train%20Acc%3A%20%7Btrain_acc%3A.4f%7D%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20val_loss%2C%20val_acc%20%3D%20evaluate(model%2C%20criterion%2C%20val_loader)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20validation_history%5B%22loss%22%5D.append(train_loss)%0A%20%20%20%20%20%20%20%20%20%20%20%20validation_history%5B%22accuracy%22%5D.append(train_acc)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20val_acc%20%3E%20best_val_accuracy%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20best_val_accuracy%20%3D%20val_acc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.save(model.state_dict()%2C%20checkpoint_filename)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Checkpoint%20saved%3A%20%7Bcheckpoint_filename%7D%22)%0A%0A%20%20%20%20%20%20%20%20return%20train_history%2C%20validation_history%0A%0A%20%20%20%20def%20evaluate(%0A%20%20%20%20%20%20%20%20model%3A%20nn.Module%2C%0A%20%20%20%20%20%20%20%20criterion%3A%20nn.CrossEntropyLoss%2C%0A%20%20%20%20%20%20%20%20val_loader%3A%20DataLoader%0A%20%20%20%20)%20-%3E%20tuple%5Bfloat%5D%3A%0A%20%20%20%20%20%20%20%20model.eval()%0A%20%20%20%20%20%20%20%20val_loss%20%3D%200.0%0A%20%20%20%20%20%20%20%20val_correct%20%3D%200%0A%20%20%20%20%20%20%20%20val_total%20%3D%200%0A%0A%20%20%20%20%20%20%20%20with%20torch.no_grad()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20inputs%2C%20labels%20in%20val_loader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20inputs%2C%20labels%20%3D%20inputs.to(get_device())%2C%20labels.to(get_device())%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20labels%20%3D%20labels.float().unsqueeze(1)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20outputs%20%3D%20model(inputs)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss%20%3D%20criterion(outputs%2C%20labels)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20val_loss%20%2B%3D%20loss.item()%20*%20inputs.size(0)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20predicted%20%3D%20(torch.sigmoid(outputs)%20%3E%200.5).float()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20val_total%20%2B%3D%20labels.size(0)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20val_correct%20%2B%3D%20(predicted%20%3D%3D%20labels).sum().item()%0A%0A%20%20%20%20%20%20%20%20val_loss%20%2F%3D%20len(val_loader)%0A%20%20%20%20%20%20%20%20val_acc%20%3D%20val_correct%20%2F%20val_total%0A%20%20%20%20%20%20%20%20print(f%22%20%20Val%20Loss%3A%20%7Bval_loss%3A.4f%7D%2C%20Val%20Acc%3A%20%7Bval_acc%3A.4f%7D%22)%0A%0A%20%20%20%20%20%20%20%20return%20val_loss%2C%20val_acc%0A%20%20%20%20return%20evaluate%2C%20get_device%2C%20optim%2C%20train%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20*%20Use%20%60batch_size%3D20%60%0A%20%20%20%20*%20Use%20%60shuffle%3DTrue%60%20for%20both%20training%2C%20but%20%60False%60%20for%20test.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Image%2C%20get_transforms)%3A%0A%20%20%20%20import%20os%0A%20%20%20%20from%20torch.utils.data%20import%20Dataset%2C%20DataLoader%0A%0A%20%20%20%20class%20HomeworkDataset(Dataset)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20data_dir%2C%20transform%3DNone)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.data_dir%20%3D%20data_dir%0A%20%20%20%20%20%20%20%20%20%20%20%20self.transform%20%3D%20transform%0A%20%20%20%20%20%20%20%20%20%20%20%20self.image_paths%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.labels%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.classes%20%3D%20sorted(os.listdir(data_dir))%0A%20%20%20%20%20%20%20%20%20%20%20%20self.class_to_idx%20%3D%20%7Bcls%3A%20i%20for%20i%2C%20cls%20in%20enumerate(self.classes)%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20label_name%20in%20self.classes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20label_dir%20%3D%20os.path.join(data_dir%2C%20label_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20img_name%20in%20os.listdir(label_dir)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.image_paths.append(os.path.join(label_dir%2C%20img_name))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.labels.append(self.class_to_idx%5Blabel_name%5D)%0A%0A%20%20%20%20%20%20%20%20def%20__len__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20len(self.image_paths)%0A%0A%20%20%20%20%20%20%20%20def%20__getitem__(self%2C%20idx)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20img_path%20%3D%20self.image_paths%5Bidx%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20image%20%3D%20Image.open(img_path).convert('RGB')%0A%20%20%20%20%20%20%20%20%20%20%20%20label%20%3D%20self.labels%5Bidx%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20self.transform%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20image%20%3D%20self.transform(image)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20image%2C%20label%0A%0A%20%20%20%20def%20get_dataloader(split%3A%20str%2C%20batch_size%3A%20int%20%3D%2020%2C%20shuffle%3A%20bool%20%3D%20True)%20-%3E%20DataLoader%3A%0A%20%20%20%20%20%20%20%20dataset%20%3D%20HomeworkDataset(%0A%20%20%20%20%20%20%20%20%20%20%20%20data_dir%3Df%22.%2Fmodule-8%2Fdata%2Fhomework%2F%7Bsplit%7D%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transform%3Dget_transforms()%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20return%20DataLoader(dataset%2C%20batch_size%20%3D%20batch_size%2C%20shuffle%20%3D%20shuffle)%0A%0A%20%20%20%20train_loader%20%3D%20get_dataloader(%22train%22%2C%20shuffle%3DTrue)%0A%20%20%20%20val_loader%20%3D%20get_dataloader(%22test%22%2C%20shuffle%3DFalse)%0A%20%20%20%20return%20DataLoader%2C%20HomeworkDataset%2C%20train_loader%2C%20val_loader%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22Now%20fit%20the%20model.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20BinaryClassification%2C%0A%20%20%20%20evaluate%2C%0A%20%20%20%20get_device%2C%0A%20%20%20%20nn%2C%0A%20%20%20%20optim%2C%0A%20%20%20%20torch%2C%0A%20%20%20%20train%2C%0A%20%20%20%20train_loader%2C%0A%20%20%20%20val_loader%2C%0A)%3A%0A%20%20%20%20from%20pathlib%20import%20Path%0A%0A%20%20%20%20weights_filename%20%3D%20%22.%2Fmodule-8%2Fdata%2Fhomework-model.torch%22%0A%0A%20%20%20%20def%20get_classifier()%20-%3E%20tuple%5Bnn.Module%2C%20optim.Adam%2C%20nn.CrossEntropyLoss%5D%3A%0A%20%20%20%20%20%20%20%20device%20%3D%20get_device()%0A%0A%20%20%20%20%20%20%20%20model%20%3D%20BinaryClassification()%0A%20%20%20%20%20%20%20%20model.to(device)%0A%0A%20%20%20%20%20%20%20%20optimizer%20%3D%20optim.SGD(model.parameters()%2C%20lr%3D0.002%2C%20momentum%3D0.8)%0A%20%20%20%20%20%20%20%20criterion%20%3D%20nn.BCEWithLogitsLoss()%0A%0A%20%20%20%20%20%20%20%20return%20model%2C%20optimizer%2C%20criterion%0A%0A%20%20%20%20%23%20This%20values%20were%20manually%20written%20after%20a%20train%20execution%0A%20%20%20%20%23%20Running%20the%20training%20process%20will%20reset%20them%0A%20%20%20%20train_history%20%3D%20%7B%22accuracy%22%3A%20%5B0.7965%2C%200.7965%5D%2C%20%22loss%22%3A%20%5B-2.948%2C%202.948%5D%7D%0A%20%20%20%20validation_history%20%3D%20%7B%22accuracy%22%3A%20%5B%5D%2C%20%22loss%22%3A%20%5B%5D%7D%0A%0A%20%20%20%20if%20not%20Path(weights_filename).exists()%3A%0A%20%20%20%20%20%20%20%20print(%22The%20model%20weights%20were%20not%20found%2C%20so%20the%20model%20will%20be%20trained%22)%0A%20%20%20%20%20%20%20%20model%2C%20optimizer%2C%20criterion%20%3D%20get_classifier()%0A%20%20%20%20%20%20%20%20train_history%2C%20validation_history%20%3D%20train(%0A%20%20%20%20%20%20%20%20%20%20%20%20model%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20optimizer%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20criterion%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20train_loader%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20val_loader%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20checkpoint_filename%20%3D%20weights_filename%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20num_epochs%20%3D%2010%2C%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20print(%22The%20model%20weights%20were%20found%2C%20so%20the%20model%20weights%20will%20be%20loaded%20and%20the%20model%20will%20be%20evaluated%22)%0A%20%20%20%20%20%20%20%20model%2C%20optimizer%2C%20criterion%20%3D%20get_classifier()%0A%20%20%20%20%20%20%20%20model.load_state_dict(torch.load(weights_filename%2C%20weights_only%3DTrue))%0A%20%20%20%20%20%20%20%20evaluate(%0A%20%20%20%20%20%20%20%20%20%20%20%20model%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20criterion%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20val_loader%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20train_history%2C%20validation_history%0A%20%20%20%20return%20Path%2C%20criterion%2C%20get_classifier%2C%20model%2C%20optimizer%2C%20train_history%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Question%203%0A%0A%20%20%20%20What%20is%20the%20median%20of%20training%20accuracy%20for%20all%20the%20epochs%20for%20this%20model%3F%0A%0A%20%20%20%20*%200.05%0A%20%20%20%20*%200.12%0A%20%20%20%20*%200.40%0A%20%20%20%20*%200.84%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22After%20a%20training%2C%20the%20following%20expression%20returned%200.7965%2C%20so%20the%20closest%20suggested%20option%20is%20**0.84**.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(np%2C%20train_history)%3A%0A%20%20%20%20np.median(train_history%5B%22accuracy%22%5D)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Question%204%0A%0A%20%20%20%20What%20is%20the%20standard%20deviation%20of%20training%20loss%20for%20all%20the%20epochs%20for%20this%20model%3F%0A%0A%20%20%20%20*%200.007%0A%20%20%20%20*%200.078%0A%20%20%20%20*%200.171%0A%20%20%20%20*%201.710%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22After%20a%20training%2C%20the%20following%20expression%20returned%202.948%2C%20so%20the%20closest%20suggested%20option%20is%20**1.710**.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(np%2C%20train_history)%3A%0A%20%20%20%20np.std(train_history%5B%22loss%22%5D)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Data%20Augmentation%0A%0A%20%20%20%20For%20the%20next%20two%20questions%2C%20we'll%20generate%20more%20data%20using%20data%20augmentations.%20%0A%0A%20%20%20%20Add%20the%20following%20augmentations%20to%20your%20training%20data%20generator%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20transforms.RandomRotation(50)%2C%0A%20%20%20%20transforms.RandomResizedCrop(200%2C%20scale%3D(0.9%2C%201.0)%2C%20ratio%3D(0.9%2C%201.1))%2C%0A%20%20%20%20transforms.RandomHorizontalFlip()%2C%0A%20%20%20%20%60%60%60%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(transforms)%3A%0A%20%20%20%20def%20get_augmented_transforms()%3A%0A%20%20%20%20%20%20%20%20return%20transforms.Compose(%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.RandomRotation(50)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.RandomResizedCrop(200%2C%20scale%3D(0.9%2C%201.0)%2C%20ratio%3D(0.9%2C%201.1))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.RandomHorizontalFlip()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.Resize((200%2C%20200))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.ToTensor()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transforms.Normalize(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mean%3D%5B0.485%2C%200.456%2C%200.406%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20std%3D%5B0.229%2C%200.224%2C%200.225%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%5D)%0A%20%20%20%20return%20(get_augmented_transforms%2C)%0A%0A%0A%40app.cell%0Adef%20_(DataLoader%2C%20HomeworkDataset%2C%20get_augmented_transforms)%3A%0A%20%20%20%20def%20get_augmented_dataloader(split%3A%20str%2C%20batch_size%3A%20int%20%3D%2020%2C%20shuffle%3A%20bool%20%3D%20True)%20-%3E%20DataLoader%3A%0A%20%20%20%20%20%20%20%20dataset%20%3D%20HomeworkDataset(%0A%20%20%20%20%20%20%20%20%20%20%20%20data_dir%3Df%22.%2Fmodule-8%2Fdata%2Fhomework%2F%7Bsplit%7D%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transform%3Dget_augmented_transforms()%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20return%20DataLoader(dataset%2C%20batch_size%20%3D%20batch_size%2C%20shuffle%20%3D%20shuffle)%0A%0A%20%20%20%20train_augmented_loader%20%3D%20get_augmented_dataloader(%22train%22%2C%20shuffle%3DTrue)%0A%20%20%20%20val_augmented_loader%20%3D%20get_augmented_dataloader(%22test%22%2C%20shuffle%3DFalse)%0A%20%20%20%20return%20train_augmented_loader%2C%20val_augmented_loader%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Question%205%20%0A%0A%20%20%20%20Let's%20train%20our%20model%20for%2010%20more%20epochs%20using%20the%20same%20code%20as%20previously.%0A%0A%20%20%20%20%3E%20**Note%3A**%20make%20sure%20you%20don't%20re-create%20the%20model.%0A%20%20%20%20%3E%20we%20want%20to%20continue%20training%20the%20model%20we%20already%20started%20training.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20Path%2C%0A%20%20%20%20criterion%2C%0A%20%20%20%20evaluate%2C%0A%20%20%20%20get_classifier%2C%0A%20%20%20%20model%2C%0A%20%20%20%20optimizer%2C%0A%20%20%20%20torch%2C%0A%20%20%20%20train%2C%0A%20%20%20%20train_augmented_loader%2C%0A%20%20%20%20val_augmented_loader%2C%0A)%3A%0A%20%20%20%20augmented_weights_filename%20%3D%20%22.%2Fmodule-8%2Fdata%2Fhomework-augmented_model.torch%22%0A%0A%20%20%20%20%23%20This%20values%20were%20manually%20written%20after%20a%20train%20execution%0A%20%20%20%20%23%20Running%20the%20training%20process%20will%20reset%20them%0A%20%20%20%20augmented_train_history%20%3D%20%7B%22accuracy%22%3A%20%5B%5D%2C%20%22loss%22%3A%20%5B10.44%5D%7D%0A%20%20%20%20augmented_validation_history%20%3D%20%7B%22accuracy%22%3A%20%5B0.7523%2C%200.7523%2C%200.7523%2C%200.7523%2C%200.7523%2C%200.7523%5D%2C%20%22loss%22%3A%20%5B%5D%7D%0A%0A%20%20%20%20if%20not%20Path(augmented_weights_filename).exists()%3A%0A%20%20%20%20%20%20%20%20print(%22The%20model%20weights%20were%20not%20found%2C%20so%20the%20model%20will%20be%20trained%22)%0A%20%20%20%20%20%20%20%20augmented_train_history%2C%20augmented_validation_history%20%3D%20train(%0A%20%20%20%20%20%20%20%20%20%20%20%20model%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20optimizer%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20criterion%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20train_augmented_loader%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20val_augmented_loader%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20checkpoint_filename%20%3D%20augmented_weights_filename%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20num_epochs%20%3D%2010%2C%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20print(%22The%20model%20weights%20were%20found%2C%20so%20the%20model%20weights%20will%20be%20loaded%20and%20the%20model%20will%20be%20evaluated%22)%0A%20%20%20%20%20%20%20%20augmented_model%2C%20augmented_optimizer%2C%20augmented_criterion%20%3D%20get_classifier()%0A%20%20%20%20%20%20%20%20augmented_model.load_state_dict(torch.load(augmented_weights_filename%2C%20weights_only%3DTrue))%0A%20%20%20%20%20%20%20%20evaluate(%0A%20%20%20%20%20%20%20%20%20%20%20%20augmented_model%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20augmented_criterion%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20val_augmented_loader%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20augmented_train_history%2C%20augmented_validation_history%0A%20%20%20%20return%20augmented_train_history%2C%20augmented_validation_history%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20What%20is%20the%20mean%20of%20test%20loss%20for%20all%20the%20epochs%20for%20the%20model%20trained%20with%20augmentations%3F%0A%0A%20%20%20%20*%200.008%0A%20%20%20%20*%200.08%0A%20%20%20%20*%200.88%0A%20%20%20%20*%208.88%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22The%20mean%20of%20the%20loss%20for%20the%20augmented%20epochs%20is%2010.44.%20The%20closest%20suggested%20option%20is%20**8.88**.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(augmented_train_history%2C%20np)%3A%0A%20%20%20%20np.mean(augmented_train_history%5B%22loss%22%5D)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%23%20Question%206%0A%0A%20%20%20%20What's%20the%20average%20of%20test%20accuracy%20for%20the%20last%205%20epochs%20(from%206%20to%2010)%0A%20%20%20%20for%20the%20model%20trained%20with%20augmentations%3F%0A%0A%20%20%20%20*%200.08%0A%20%20%20%20*%200.28%0A%20%20%20%20*%200.68%0A%20%20%20%20*%200.98%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22The%20average%20test%20accuracy%20for%20the%20last%205%20epochs%20trained%20with%20augmentations%20is%200.7523%2C%20and%20the%20closest%20suggested%20option%20is%20**0.68**.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(augmented_validation_history%2C%20np)%3A%0A%20%20%20%20np.average(augmented_validation_history%5B%22accuracy%22%5D%5B5%3A%5D)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%20Submit%20the%20results%0A%0A%20%20%20%20*%20Submit%20your%20results%20here%3A%20https%3A%2F%2Fcourses.datatalks.club%2Fml-zoomcamp-2025%2Fhomework%2Fhw08%0A%20%20%20%20*%20If%20your%20answer%20doesn't%20match%20options%20exactly%2C%20select%20the%20closest%20one.%20If%20the%20answer%20is%20exactly%20in%20between%20two%20options%2C%20select%20the%20higher%20value.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">48b0dda0f160f4c7caf66250d2c595f181ca8309cc47645b9dfe44033c56ff08</marimo-code-hash>
</body>
</html>
